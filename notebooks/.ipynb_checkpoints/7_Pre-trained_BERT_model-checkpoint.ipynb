{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Pre-trained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, my aim is to try pre-trained model (BERT) to figure out how results will change when I use pre-trained model. \n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a model which released in late 2018 for transfer learning in NLP. Advantages of pre-trained BERT;\n",
    "\n",
    "- Model already has a lot of information so less time needs to tune model.\n",
    "- It is already pre-trained so less data is needed to train the model.\n",
    "- Because of simple fine-tuning procedure, it generally gives better results.\n",
    "\n",
    "To get my results more quickly, I used Google Colab in this model with offered free GPU. \n",
    "\n",
    "To learn how to use BERT, I used the tutorial below,\n",
    "\n",
    "http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "brprw0cBT-2C",
    "outputId": "46985094-e8ae-4b42-e732-51281a23ec41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# find the exact GPU name and assign it to this notebook\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# To check the device name is found like below\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IAZGL6_fUFNq",
    "outputId": "4ba216f4-ada5-4e48-f34f-861c7f41ca1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If GPU is available setting to use this\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Setting the PyTorch to use GPU as memory\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# To check is GPU is not found\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have to download transformers package because BERT can be used with it. Transformers library contains PyTorch and Tensorflow implementations, pre-trained model weights, usage scripts and conversion utilities for more than 10 different models, details can be found [here](https://huggingface.co/transformers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "-N6J8qsxUyKO",
    "outputId": "a004ffd8-a8ca-47cf-8eac-29fc2eebc73d"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use pandas dataframe\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download my data to Google Colab, I need to connect Colab with my Drive. So, I used the cell below and put the confirmation code to this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "jVbeyyADWb9E",
    "outputId": "1f1538be-fe38-4707-e3c7-c2ebc275799b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrgHKJkuViFo"
   },
   "outputs": [],
   "source": [
    "# taking data to df from Google Drive\n",
    "path = '/content/drive/My Drive/train/train.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "cDaK2F8IXob8",
    "outputId": "678a6597-ee6e-42c3-a644-b1d079b8c902",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_clean    0\n",
       "sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # to check the null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will assign my text and target values to lists to prepare them to model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSYeOlrUX74v"
   },
   "outputs": [],
   "source": [
    "text = df['review_clean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_TCmxQIYUV2"
   },
   "outputs": [],
   "source": [
    "target = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to split my text to tokens to feed it to BERT. I also set lower case True, just in case because I have already preprocessed lower-case before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "d7d24741db9a4cf59b701080fdc708e4",
      "fdbf18eb52a84873b92871328d41e6c6",
      "3560dab447db4fd7ae693b3c71bc110e",
      "73ac4055d22b43ceb0975a78af928f21",
      "943ed645d2084cfaa302247bcf5ea00a",
      "28f9d6f70b774a68882e79c809e1f5be",
      "881a66794b814e548fe39b2ccd7d80b1",
      "0e28fab1deae4b509e1b2e74dd362c3d"
     ]
    },
    "colab_type": "code",
    "id": "mzSyvFA5YYZp",
    "outputId": "85bc93ad-cb0c-4c49-e64a-4452c0ca2d53"
   },
   "outputs": [],
   "source": [
    "# using Bert-Tokenizer to tokenize text \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will try tokenizer firstly to first text of my data to check and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "UAytA7woYd-F",
    "outputId": "40154b88-d281-4409-dec4-e12804015215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  this is a cute little book that is fairly short and easy to read this author fell in love with a silver camper bought it refurbished it and off she went to camp for six months those six months turned into a trip of a life time and a move across the country by the time it was over\n",
      "\n",
      "i give it a little bit lower score than others because i didnt find it laugh out loud hilarious it was funny in a cute way and for someone who owns a camper and goes camping often much of this book is right on target about how not to  and it was right on target about life in a campground\n",
      "\n",
      "overall this is an enjoyable book it is cute and clever it is not a long read and it is right on target in many ways \n",
      "enjoy\n",
      "Tokenized:  ['this', 'is', 'a', 'cute', 'little', 'book', 'that', 'is', 'fairly', 'short', 'and', 'easy', 'to', 'read', 'this', 'author', 'fell', 'in', 'love', 'with', 'a', 'silver', 'camp', '##er', 'bought', 'it', 'refurbished', 'it', 'and', 'off', 'she', 'went', 'to', 'camp', 'for', 'six', 'months', 'those', 'six', 'months', 'turned', 'into', 'a', 'trip', 'of', 'a', 'life', 'time', 'and', 'a', 'move', 'across', 'the', 'country', 'by', 'the', 'time', 'it', 'was', 'over', 'i', 'give', 'it', 'a', 'little', 'bit', 'lower', 'score', 'than', 'others', 'because', 'i', 'didn', '##t', 'find', 'it', 'laugh', 'out', 'loud', 'hilarious', 'it', 'was', 'funny', 'in', 'a', 'cute', 'way', 'and', 'for', 'someone', 'who', 'owns', 'a', 'camp', '##er', 'and', 'goes', 'camping', 'often', 'much', 'of', 'this', 'book', 'is', 'right', 'on', 'target', 'about', 'how', 'not', 'to', 'and', 'it', 'was', 'right', 'on', 'target', 'about', 'life', 'in', 'a', 'campground', 'overall', 'this', 'is', 'an', 'enjoyable', 'book', 'it', 'is', 'cute', 'and', 'clever', 'it', 'is', 'not', 'a', 'long', 'read', 'and', 'it', 'is', 'right', 'on', 'target', 'in', 'many', 'ways', 'enjoy']\n",
      "Token IDs:  [2023, 2003, 1037, 10140, 2210, 2338, 2008, 2003, 7199, 2460, 1998, 3733, 2000, 3191, 2023, 3166, 3062, 1999, 2293, 2007, 1037, 3165, 3409, 2121, 4149, 2009, 18662, 2009, 1998, 2125, 2016, 2253, 2000, 3409, 2005, 2416, 2706, 2216, 2416, 2706, 2357, 2046, 1037, 4440, 1997, 1037, 2166, 2051, 1998, 1037, 2693, 2408, 1996, 2406, 2011, 1996, 2051, 2009, 2001, 2058, 1045, 2507, 2009, 1037, 2210, 2978, 2896, 3556, 2084, 2500, 2138, 1045, 2134, 2102, 2424, 2009, 4756, 2041, 5189, 26316, 2009, 2001, 6057, 1999, 1037, 10140, 2126, 1998, 2005, 2619, 2040, 8617, 1037, 3409, 2121, 1998, 3632, 13215, 2411, 2172, 1997, 2023, 2338, 2003, 2157, 2006, 4539, 2055, 2129, 2025, 2000, 1998, 2009, 2001, 2157, 2006, 4539, 2055, 2166, 1999, 1037, 29144, 3452, 2023, 2003, 2019, 22249, 2338, 2009, 2003, 10140, 1998, 12266, 2009, 2003, 2025, 1037, 2146, 3191, 1998, 2009, 2003, 2157, 2006, 4539, 1999, 2116, 3971, 5959]\n"
     ]
    }
   ],
   "source": [
    "# to see the original text\n",
    "print(' Original: ', text[0])\n",
    "\n",
    "# to see the tokenized text\n",
    "print('Tokenized: ', tokenizer.tokenize(text[0]))\n",
    "\n",
    "# to see the token ids of text\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am sure my tokenizer is working and I will apply it to whole rows. In addition to this, BERT needs special formatting such as it needs special tokens at the end of the each text and at the begining of the each text. To prepare my text to BERT, I will do some preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Text for BERT Formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step;\n",
    "\n",
    "- I will add special tokens to the begining and at the end of each text. At the end of the each text, I have to add [SEP] token. Also, [CLS] token will be added to begining of the each sentence for classification problems. \n",
    "- I will set all texts to a single constant length. For BERT, all texts must be padded to fixed lenght and it can be 512 token maximum. Padding is doing with [PAD] token, which is indexed as 0 in BERT vocabulary. If the tokens of the text is less than maximum token number [PAD] token assigns after the [SEP] token until reaching maximum token number. Also, attention mask value for these [PAD] tokens are 0. Because, if the token is padding, attention mask is 1, if not it is 0. In this notebook, I tried both 512 and 128 max lenght tokens. Training and evaluations of 512 took 2 times more than 128 and the results were not significantly different. So, I advice to set 128, if somebody wants to run this notebook with same data. The handycap of setting max length to 512 is that for my data, I also have some texts which are longer than 512, but when I checked their number, I found them not too much. So I assume that if I set the lenght to 512, I will not lose too much information. This is one of the weekest points of BERT, it allows maximum 512 tokens.\n",
    "- I will map tokens to their corresponding ids.\n",
    "\n",
    "To begin these steps, I will use .encode tool of BertTokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "9Vm0MhHKYkIa",
    "outputId": "289f9f79-9abf-44c2-fae0-a2afb3a1a6d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  this is a cute little book that is fairly short and easy to read this author fell in love with a silver camper bought it refurbished it and off she went to camp for six months those six months turned into a trip of a life time and a move across the country by the time it was over\n",
      "\n",
      "i give it a little bit lower score than others because i didnt find it laugh out loud hilarious it was funny in a cute way and for someone who owns a camper and goes camping often much of this book is right on target about how not to  and it was right on target about life in a campground\n",
      "\n",
      "overall this is an enjoyable book it is cute and clever it is not a long read and it is right on target in many ways \n",
      "enjoy\n",
      "Token IDs: [101, 2023, 2003, 1037, 10140, 2210, 2338, 2008, 2003, 7199, 2460, 1998, 3733, 2000, 3191, 2023, 3166, 3062, 1999, 2293, 2007, 1037, 3165, 3409, 2121, 4149, 2009, 18662, 2009, 1998, 2125, 2016, 2253, 2000, 3409, 2005, 2416, 2706, 2216, 2416, 2706, 2357, 2046, 1037, 4440, 1997, 1037, 2166, 2051, 1998, 1037, 2693, 2408, 1996, 2406, 2011, 1996, 2051, 2009, 2001, 2058, 1045, 2507, 2009, 1037, 2210, 2978, 2896, 3556, 2084, 2500, 2138, 1045, 2134, 2102, 2424, 2009, 4756, 2041, 5189, 26316, 2009, 2001, 6057, 1999, 1037, 10140, 2126, 1998, 2005, 2619, 2040, 8617, 1037, 3409, 2121, 1998, 3632, 13215, 2411, 2172, 1997, 2023, 2338, 2003, 2157, 2006, 4539, 2055, 2129, 2025, 2000, 1998, 2009, 2001, 2157, 2006, 4539, 2055, 2166, 1999, 1037, 29144, 3452, 2023, 2003, 2019, 102]\n"
     ]
    }
   ],
   "source": [
    "# To tokenize texts and map the tokens to corresponding IDs\n",
    "input_ids = [] # creating empty list to keep input ids\n",
    "\n",
    "# Loop for each element in text\n",
    "for element in text:\n",
    "\n",
    "    encoded_text = tokenizer.encode(element,add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                         max_length = 128)  # setting all sentences to max_len\n",
    "                                \n",
    "    # firstly I tried it for 512 and I tried for 128, last trial belongs to 128 so values are for 128\n",
    "    # there were no significant difference between 128 or 512 \n",
    "    \n",
    "    # keeping encoded texts as list\n",
    "    input_ids.append(encoded_text)\n",
    "\n",
    "# printing to check\n",
    "print('Original: ', text[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For padding part, I will use pad_sequences function from keras.preprocessing.sequence library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Cp9BPRd1tMIo",
    "outputId": "a3f2ca3f-f5f6-44ae-cc46-817cd69cfb9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 128 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "max_length = 128 # for 512, I set it to 512\n",
    "\n",
    "print(f'\\nPadding/truncating all sentences to {max_length} values...')\n",
    "\n",
    "print(f'\\nPadding token: \"{tokenizer.pad_token}\", ID: {tokenizer.pad_token_id}')\n",
    "\n",
    "# pad sequence function for pad tokens and assign zeros for shorter than max lenght\n",
    "input_ids = pad_sequences(input_ids, maxlen=max_length, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ojtKhuPatXT"
   },
   "outputs": [],
   "source": [
    "# To keep attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Loop for each element in inputs\n",
    "for element in input_ids:\n",
    "    \n",
    "    #   I assigned the empty tokens to 0 in above cell so if token is 0, setting the mask zero\n",
    "    #   If token is larger than zero it means it is real token ID and set it to 1\n",
    "    att_mask = [int(token_id > 0) for token_id in element]\n",
    "    \n",
    "    # keeping attention masks\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have to split my data for validation. I choose same random state and test size to compare my results with previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F92-y3sJawbO"
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, target, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "# Splitting masks also with same parameters\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, target,\n",
    "                                             random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will concert all inputs and targets to torch tensors, it is required datatype for BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdQSuZ94a7f2"
   },
   "outputs": [],
   "source": [
    "# for inputs\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "# for target values\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "# for masks\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8m5nE_wKbSCA"
   },
   "outputs": [],
   "source": [
    "batch_size = 32 # in tutorial it is recommended that to set 16 or 32. I choose 32 for more batches\n",
    "\n",
    "# creating dataloader for train set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
    "\n",
    "# creating dataloader for validation set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have formatted data for BERT, so I wil begin fine tuning of BERT. BERT has many classes for fine tuning, such as BertModel, BertForNextSentencePrediction etc. In this notebook, I will use BertForSequenceClassification. This is the simple BERT model with an added single layer on top for classification. There are different pre-trained BERT models. “bert-base-uncased” is the version that has only lowercase letters (“uncased”) and is the smaller version of the two (“base” vs “large”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KwAKvngYbYSB",
    "outputId": "0cf0bbc3-e255-42b7-c193-2797f875abb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # use base with lower case\n",
    "    num_labels = 2, # my target is binary so I choose 2   \n",
    "    output_attentions = False, # model does not return attentions weights\n",
    "    output_hidden_states = False) # for returning all hidden-states\n",
    "\n",
    "# inform Pytorch to run model in GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand parameters and what embedding layer, transformers and output layer contains, I will print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "Oh4ApNSjbcAS",
    "outputId": "57ba1d32-2ab5-4321-875f-aa6ea6b6d146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune the optimizer, it is recommended in tutorial to choose learning rate for AdamW optimizer 5e-5, 3e-5 or 2e-5. I prefer 2-e5 to be more precise. 1e-8 is also very small for epsilon value but it is good to prevent any division by zero in the implementation, detailed [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KekfSfNPbnR_"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPUUU-AnbuPd"
   },
   "outputs": [],
   "source": [
    "# 5 epoches is too much for this model, but to get better results and make sure model is learning or not, I choose it\n",
    "epochs = 5\n",
    "\n",
    "# number of steps data loader times epoch number\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# setting scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZM2FxwESb0Ru"
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(pred, true):\n",
    "    '''function for flatten accuracy'''\n",
    "    pred_flat = np.argmax(pred, axis=1).flatten()\n",
    "    labels_flat = true.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9EkYZgHb8nH"
   },
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    to see time taking second and returns time as string with hour, min, sec\n",
    "    '''\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rX2Qzc_7ws73"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My training cell generally consists of two parts. First one for training, second one for evaluation from validation data. Training part is unpacking my data, loading data to GPU, clear gradients which calculated in the previous pass. As a default, gradients are kept in PyTorch, so I will clear out them explicitly. There are forward and backward passes also in training loop because forward is needed for feeding input data through network and backward for backpropagation. And last steps for training part is optimizer and observe variables for monitoring progress.\n",
    "\n",
    "For evaluation part, data is unpacked again, it is loaded GPU like train part. There is forward pass to feed input data through network and calculating progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_MUc3js8wu8T",
    "outputId": "b7b0aaee-6f57-4654-b28a-05c085b5929d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of  2,000.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  2,000.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  2,000.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  2,000.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  2,000.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  2,000.    Elapsed: 0:01:30.\n",
      "  Batch   280  of  2,000.    Elapsed: 0:01:45.\n",
      "  Batch   320  of  2,000.    Elapsed: 0:02:01.\n",
      "  Batch   360  of  2,000.    Elapsed: 0:02:16.\n",
      "  Batch   400  of  2,000.    Elapsed: 0:02:31.\n",
      "  Batch   440  of  2,000.    Elapsed: 0:02:46.\n",
      "  Batch   480  of  2,000.    Elapsed: 0:03:01.\n",
      "  Batch   520  of  2,000.    Elapsed: 0:03:16.\n",
      "  Batch   560  of  2,000.    Elapsed: 0:03:31.\n",
      "  Batch   600  of  2,000.    Elapsed: 0:03:46.\n",
      "  Batch   640  of  2,000.    Elapsed: 0:04:01.\n",
      "  Batch   680  of  2,000.    Elapsed: 0:04:16.\n",
      "  Batch   720  of  2,000.    Elapsed: 0:04:31.\n",
      "  Batch   760  of  2,000.    Elapsed: 0:04:46.\n",
      "  Batch   800  of  2,000.    Elapsed: 0:05:01.\n",
      "  Batch   840  of  2,000.    Elapsed: 0:05:16.\n",
      "  Batch   880  of  2,000.    Elapsed: 0:05:31.\n",
      "  Batch   920  of  2,000.    Elapsed: 0:05:46.\n",
      "  Batch   960  of  2,000.    Elapsed: 0:06:01.\n",
      "  Batch 1,000  of  2,000.    Elapsed: 0:06:16.\n",
      "  Batch 1,040  of  2,000.    Elapsed: 0:06:31.\n",
      "  Batch 1,080  of  2,000.    Elapsed: 0:06:46.\n",
      "  Batch 1,120  of  2,000.    Elapsed: 0:07:01.\n",
      "  Batch 1,160  of  2,000.    Elapsed: 0:07:16.\n",
      "  Batch 1,200  of  2,000.    Elapsed: 0:07:31.\n",
      "  Batch 1,240  of  2,000.    Elapsed: 0:07:46.\n",
      "  Batch 1,280  of  2,000.    Elapsed: 0:08:02.\n",
      "  Batch 1,320  of  2,000.    Elapsed: 0:08:17.\n",
      "  Batch 1,360  of  2,000.    Elapsed: 0:08:32.\n",
      "  Batch 1,400  of  2,000.    Elapsed: 0:08:47.\n",
      "  Batch 1,440  of  2,000.    Elapsed: 0:09:02.\n",
      "  Batch 1,480  of  2,000.    Elapsed: 0:09:17.\n",
      "  Batch 1,520  of  2,000.    Elapsed: 0:09:32.\n",
      "  Batch 1,560  of  2,000.    Elapsed: 0:09:47.\n",
      "  Batch 1,600  of  2,000.    Elapsed: 0:10:02.\n",
      "  Batch 1,640  of  2,000.    Elapsed: 0:10:17.\n",
      "  Batch 1,680  of  2,000.    Elapsed: 0:10:32.\n",
      "  Batch 1,720  of  2,000.    Elapsed: 0:10:47.\n",
      "  Batch 1,760  of  2,000.    Elapsed: 0:11:02.\n",
      "  Batch 1,800  of  2,000.    Elapsed: 0:11:17.\n",
      "  Batch 1,840  of  2,000.    Elapsed: 0:11:32.\n",
      "  Batch 1,880  of  2,000.    Elapsed: 0:11:47.\n",
      "  Batch 1,920  of  2,000.    Elapsed: 0:12:02.\n",
      "  Batch 1,960  of  2,000.    Elapsed: 0:12:17.\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:12:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of  2,000.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  2,000.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  2,000.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  2,000.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  2,000.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  2,000.    Elapsed: 0:01:30.\n",
      "  Batch   280  of  2,000.    Elapsed: 0:01:45.\n",
      "  Batch   320  of  2,000.    Elapsed: 0:02:00.\n",
      "  Batch   360  of  2,000.    Elapsed: 0:02:15.\n",
      "  Batch   400  of  2,000.    Elapsed: 0:02:30.\n",
      "  Batch   440  of  2,000.    Elapsed: 0:02:45.\n",
      "  Batch   480  of  2,000.    Elapsed: 0:03:00.\n",
      "  Batch   520  of  2,000.    Elapsed: 0:03:15.\n",
      "  Batch   560  of  2,000.    Elapsed: 0:03:30.\n",
      "  Batch   600  of  2,000.    Elapsed: 0:03:45.\n",
      "  Batch   640  of  2,000.    Elapsed: 0:04:00.\n",
      "  Batch   680  of  2,000.    Elapsed: 0:04:15.\n",
      "  Batch   720  of  2,000.    Elapsed: 0:04:30.\n",
      "  Batch   760  of  2,000.    Elapsed: 0:04:45.\n",
      "  Batch   800  of  2,000.    Elapsed: 0:05:00.\n",
      "  Batch   840  of  2,000.    Elapsed: 0:05:15.\n",
      "  Batch   880  of  2,000.    Elapsed: 0:05:30.\n",
      "  Batch   920  of  2,000.    Elapsed: 0:05:45.\n",
      "  Batch   960  of  2,000.    Elapsed: 0:06:00.\n",
      "  Batch 1,000  of  2,000.    Elapsed: 0:06:15.\n",
      "  Batch 1,040  of  2,000.    Elapsed: 0:06:30.\n",
      "  Batch 1,080  of  2,000.    Elapsed: 0:06:45.\n",
      "  Batch 1,120  of  2,000.    Elapsed: 0:07:00.\n",
      "  Batch 1,160  of  2,000.    Elapsed: 0:07:15.\n",
      "  Batch 1,200  of  2,000.    Elapsed: 0:07:30.\n",
      "  Batch 1,240  of  2,000.    Elapsed: 0:07:45.\n",
      "  Batch 1,280  of  2,000.    Elapsed: 0:08:00.\n",
      "  Batch 1,320  of  2,000.    Elapsed: 0:08:15.\n",
      "  Batch 1,360  of  2,000.    Elapsed: 0:08:30.\n",
      "  Batch 1,400  of  2,000.    Elapsed: 0:08:45.\n",
      "  Batch 1,440  of  2,000.    Elapsed: 0:09:00.\n",
      "  Batch 1,480  of  2,000.    Elapsed: 0:09:15.\n",
      "  Batch 1,520  of  2,000.    Elapsed: 0:09:30.\n",
      "  Batch 1,560  of  2,000.    Elapsed: 0:09:44.\n",
      "  Batch 1,600  of  2,000.    Elapsed: 0:09:59.\n",
      "  Batch 1,640  of  2,000.    Elapsed: 0:10:14.\n",
      "  Batch 1,680  of  2,000.    Elapsed: 0:10:29.\n",
      "  Batch 1,720  of  2,000.    Elapsed: 0:10:44.\n",
      "  Batch 1,760  of  2,000.    Elapsed: 0:11:00.\n",
      "  Batch 1,800  of  2,000.    Elapsed: 0:11:15.\n",
      "  Batch 1,840  of  2,000.    Elapsed: 0:11:30.\n",
      "  Batch 1,880  of  2,000.    Elapsed: 0:11:45.\n",
      "  Batch 1,920  of  2,000.    Elapsed: 0:12:00.\n",
      "  Batch 1,960  of  2,000.    Elapsed: 0:12:15.\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:12:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of  2,000.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  2,000.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  2,000.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  2,000.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  2,000.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  2,000.    Elapsed: 0:01:30.\n",
      "  Batch   280  of  2,000.    Elapsed: 0:01:45.\n",
      "  Batch   320  of  2,000.    Elapsed: 0:02:00.\n",
      "  Batch   360  of  2,000.    Elapsed: 0:02:15.\n",
      "  Batch   400  of  2,000.    Elapsed: 0:02:30.\n",
      "  Batch   440  of  2,000.    Elapsed: 0:02:45.\n",
      "  Batch   480  of  2,000.    Elapsed: 0:03:00.\n",
      "  Batch   520  of  2,000.    Elapsed: 0:03:15.\n",
      "  Batch   560  of  2,000.    Elapsed: 0:03:30.\n",
      "  Batch   600  of  2,000.    Elapsed: 0:03:45.\n",
      "  Batch   640  of  2,000.    Elapsed: 0:04:00.\n",
      "  Batch   680  of  2,000.    Elapsed: 0:04:15.\n",
      "  Batch   720  of  2,000.    Elapsed: 0:04:30.\n",
      "  Batch   760  of  2,000.    Elapsed: 0:04:45.\n",
      "  Batch   800  of  2,000.    Elapsed: 0:05:00.\n",
      "  Batch   840  of  2,000.    Elapsed: 0:05:15.\n",
      "  Batch   880  of  2,000.    Elapsed: 0:05:30.\n",
      "  Batch   920  of  2,000.    Elapsed: 0:05:45.\n",
      "  Batch   960  of  2,000.    Elapsed: 0:06:00.\n",
      "  Batch 1,000  of  2,000.    Elapsed: 0:06:15.\n",
      "  Batch 1,040  of  2,000.    Elapsed: 0:06:30.\n",
      "  Batch 1,080  of  2,000.    Elapsed: 0:06:45.\n",
      "  Batch 1,120  of  2,000.    Elapsed: 0:07:00.\n",
      "  Batch 1,160  of  2,000.    Elapsed: 0:07:15.\n",
      "  Batch 1,200  of  2,000.    Elapsed: 0:07:30.\n",
      "  Batch 1,240  of  2,000.    Elapsed: 0:07:45.\n",
      "  Batch 1,280  of  2,000.    Elapsed: 0:08:00.\n",
      "  Batch 1,320  of  2,000.    Elapsed: 0:08:15.\n",
      "  Batch 1,360  of  2,000.    Elapsed: 0:08:30.\n",
      "  Batch 1,400  of  2,000.    Elapsed: 0:08:45.\n",
      "  Batch 1,440  of  2,000.    Elapsed: 0:09:00.\n",
      "  Batch 1,480  of  2,000.    Elapsed: 0:09:15.\n",
      "  Batch 1,520  of  2,000.    Elapsed: 0:09:30.\n",
      "  Batch 1,560  of  2,000.    Elapsed: 0:09:45.\n",
      "  Batch 1,600  of  2,000.    Elapsed: 0:10:00.\n",
      "  Batch 1,640  of  2,000.    Elapsed: 0:10:15.\n",
      "  Batch 1,680  of  2,000.    Elapsed: 0:10:30.\n",
      "  Batch 1,720  of  2,000.    Elapsed: 0:10:45.\n",
      "  Batch 1,760  of  2,000.    Elapsed: 0:11:00.\n",
      "  Batch 1,800  of  2,000.    Elapsed: 0:11:15.\n",
      "  Batch 1,840  of  2,000.    Elapsed: 0:11:30.\n",
      "  Batch 1,880  of  2,000.    Elapsed: 0:11:45.\n",
      "  Batch 1,920  of  2,000.    Elapsed: 0:12:00.\n",
      "  Batch 1,960  of  2,000.    Elapsed: 0:12:15.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:12:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of  2,000.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  2,000.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  2,000.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  2,000.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  2,000.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  2,000.    Elapsed: 0:01:30.\n",
      "  Batch   280  of  2,000.    Elapsed: 0:01:45.\n",
      "  Batch   320  of  2,000.    Elapsed: 0:02:00.\n",
      "  Batch   360  of  2,000.    Elapsed: 0:02:15.\n",
      "  Batch   400  of  2,000.    Elapsed: 0:02:30.\n",
      "  Batch   440  of  2,000.    Elapsed: 0:02:45.\n",
      "  Batch   480  of  2,000.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  2,000.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  2,000.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  2,000.    Elapsed: 0:03:44.\n",
      "  Batch   640  of  2,000.    Elapsed: 0:03:59.\n",
      "  Batch   680  of  2,000.    Elapsed: 0:04:14.\n",
      "  Batch   720  of  2,000.    Elapsed: 0:04:29.\n",
      "  Batch   760  of  2,000.    Elapsed: 0:04:44.\n",
      "  Batch   800  of  2,000.    Elapsed: 0:04:59.\n",
      "  Batch   840  of  2,000.    Elapsed: 0:05:14.\n",
      "  Batch   880  of  2,000.    Elapsed: 0:05:29.\n",
      "  Batch   920  of  2,000.    Elapsed: 0:05:44.\n",
      "  Batch   960  of  2,000.    Elapsed: 0:05:59.\n",
      "  Batch 1,000  of  2,000.    Elapsed: 0:06:14.\n",
      "  Batch 1,040  of  2,000.    Elapsed: 0:06:29.\n",
      "  Batch 1,080  of  2,000.    Elapsed: 0:06:43.\n",
      "  Batch 1,120  of  2,000.    Elapsed: 0:06:58.\n",
      "  Batch 1,160  of  2,000.    Elapsed: 0:07:13.\n",
      "  Batch 1,200  of  2,000.    Elapsed: 0:07:28.\n",
      "  Batch 1,240  of  2,000.    Elapsed: 0:07:43.\n",
      "  Batch 1,280  of  2,000.    Elapsed: 0:07:58.\n",
      "  Batch 1,320  of  2,000.    Elapsed: 0:08:13.\n",
      "  Batch 1,360  of  2,000.    Elapsed: 0:08:28.\n",
      "  Batch 1,400  of  2,000.    Elapsed: 0:08:43.\n",
      "  Batch 1,440  of  2,000.    Elapsed: 0:08:58.\n",
      "  Batch 1,480  of  2,000.    Elapsed: 0:09:13.\n",
      "  Batch 1,520  of  2,000.    Elapsed: 0:09:28.\n",
      "  Batch 1,560  of  2,000.    Elapsed: 0:09:43.\n",
      "  Batch 1,600  of  2,000.    Elapsed: 0:09:58.\n",
      "  Batch 1,640  of  2,000.    Elapsed: 0:10:13.\n",
      "  Batch 1,680  of  2,000.    Elapsed: 0:10:28.\n",
      "  Batch 1,720  of  2,000.    Elapsed: 0:10:43.\n",
      "  Batch 1,760  of  2,000.    Elapsed: 0:10:58.\n",
      "  Batch 1,800  of  2,000.    Elapsed: 0:11:13.\n",
      "  Batch 1,840  of  2,000.    Elapsed: 0:11:28.\n",
      "  Batch 1,880  of  2,000.    Elapsed: 0:11:43.\n",
      "  Batch 1,920  of  2,000.    Elapsed: 0:11:58.\n",
      "  Batch 1,960  of  2,000.    Elapsed: 0:12:13.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:12:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of  2,000.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  2,000.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  2,000.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  2,000.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  2,000.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  2,000.    Elapsed: 0:01:30.\n",
      "  Batch   280  of  2,000.    Elapsed: 0:01:45.\n",
      "  Batch   320  of  2,000.    Elapsed: 0:02:00.\n",
      "  Batch   360  of  2,000.    Elapsed: 0:02:15.\n",
      "  Batch   400  of  2,000.    Elapsed: 0:02:30.\n",
      "  Batch   440  of  2,000.    Elapsed: 0:02:45.\n",
      "  Batch   480  of  2,000.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  2,000.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  2,000.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  2,000.    Elapsed: 0:03:44.\n",
      "  Batch   640  of  2,000.    Elapsed: 0:03:59.\n",
      "  Batch   680  of  2,000.    Elapsed: 0:04:14.\n",
      "  Batch   720  of  2,000.    Elapsed: 0:04:29.\n",
      "  Batch   760  of  2,000.    Elapsed: 0:04:44.\n",
      "  Batch   800  of  2,000.    Elapsed: 0:04:59.\n",
      "  Batch   840  of  2,000.    Elapsed: 0:05:14.\n",
      "  Batch   880  of  2,000.    Elapsed: 0:05:29.\n",
      "  Batch   920  of  2,000.    Elapsed: 0:05:44.\n",
      "  Batch   960  of  2,000.    Elapsed: 0:05:59.\n",
      "  Batch 1,000  of  2,000.    Elapsed: 0:06:14.\n",
      "  Batch 1,040  of  2,000.    Elapsed: 0:06:29.\n",
      "  Batch 1,080  of  2,000.    Elapsed: 0:06:44.\n",
      "  Batch 1,120  of  2,000.    Elapsed: 0:06:59.\n",
      "  Batch 1,160  of  2,000.    Elapsed: 0:07:14.\n",
      "  Batch 1,200  of  2,000.    Elapsed: 0:07:29.\n",
      "  Batch 1,240  of  2,000.    Elapsed: 0:07:44.\n",
      "  Batch 1,280  of  2,000.    Elapsed: 0:07:59.\n",
      "  Batch 1,320  of  2,000.    Elapsed: 0:08:14.\n",
      "  Batch 1,360  of  2,000.    Elapsed: 0:08:29.\n",
      "  Batch 1,400  of  2,000.    Elapsed: 0:08:44.\n",
      "  Batch 1,440  of  2,000.    Elapsed: 0:08:59.\n",
      "  Batch 1,480  of  2,000.    Elapsed: 0:09:14.\n",
      "  Batch 1,520  of  2,000.    Elapsed: 0:09:29.\n",
      "  Batch 1,560  of  2,000.    Elapsed: 0:09:44.\n",
      "  Batch 1,600  of  2,000.    Elapsed: 0:09:59.\n",
      "  Batch 1,640  of  2,000.    Elapsed: 0:10:14.\n",
      "  Batch 1,680  of  2,000.    Elapsed: 0:10:29.\n",
      "  Batch 1,720  of  2,000.    Elapsed: 0:10:44.\n",
      "  Batch 1,760  of  2,000.    Elapsed: 0:10:59.\n",
      "  Batch 1,800  of  2,000.    Elapsed: 0:11:14.\n",
      "  Batch 1,840  of  2,000.    Elapsed: 0:11:29.\n",
      "  Batch 1,880  of  2,000.    Elapsed: 0:11:44.\n",
      "  Batch 1,920  of  2,000.    Elapsed: 0:11:59.\n",
      "  Batch 1,960  of  2,000.    Elapsed: 0:12:14.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:12:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# seed value for reproduciblity\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Keeping loss values to observe them after modeling\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch_i in range(0, epochs):\n",
    "  \n",
    "    # to see results in proper way\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # to see the time\n",
    "    t0 = time.time()\n",
    "\n",
    "    # clening loss for every epoch\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.train() # not to perform training, it changes the mode\n",
    "\n",
    "    # each batch of training data\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # setting progress for each 40 batches\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # printing progress of results\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # unpack the batch for each tensor with 'to' function\n",
    "        b_input_ids = batch[0].to(device) \n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # before backward pass, clearing previous gradinets\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # forward pass which claculates the model on this training batch\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "        \n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Report the final accuracy for this validation run.\n",
    "   \n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "6ipjiFXBmH-o",
    "outputId": "6da60d59-bdff-4532-d656-c9776bd8a2af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "weMCdBHitrOm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPBz1qYfeuLlLrzLypc46Sh",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e28fab1deae4b509e1b2e74dd362c3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f9d6f70b774a68882e79c809e1f5be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3560dab447db4fd7ae693b3c71bc110e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28f9d6f70b774a68882e79c809e1f5be",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_943ed645d2084cfaa302247bcf5ea00a",
      "value": 231508
     }
    },
    "73ac4055d22b43ceb0975a78af928f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e28fab1deae4b509e1b2e74dd362c3d",
      "placeholder": "​",
      "style": "IPY_MODEL_881a66794b814e548fe39b2ccd7d80b1",
      "value": " 232k/232k [01:50&lt;00:00, 2.10kB/s]"
     }
    },
    "881a66794b814e548fe39b2ccd7d80b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "943ed645d2084cfaa302247bcf5ea00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d7d24741db9a4cf59b701080fdc708e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3560dab447db4fd7ae693b3c71bc110e",
       "IPY_MODEL_73ac4055d22b43ceb0975a78af928f21"
      ],
      "layout": "IPY_MODEL_fdbf18eb52a84873b92871328d41e6c6"
     }
    },
    "fdbf18eb52a84873b92871328d41e6c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
