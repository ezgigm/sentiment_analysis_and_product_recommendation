{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with Different Layer Types and Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was run in Google Colab to get more quick results same time without hurting my computer.\n",
    "\n",
    "### Aim of This Notebook:\n",
    "\n",
    "My aim in this notebook is to find better results than CNN with 3-conv layers and RNN with 2-GRU layers models. So, I tried CNN with 2-conv layers and RNN with 2-CuDNNGRU layer and 2-LSTM layers.\n",
    "\n",
    "The detailed comparison of results for all 5 Keras models can be found at the end of this notebook with feature advices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8neitrJ7lqZA"
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "#tensorflow imports\n",
    "import tensorflow\n",
    "from tensorflow.python.keras import models, layers, optimizers\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "W8EBMG9Plqaa",
    "outputId": "40f2a018-a5aa-434c-c1ef-1d60f44d0e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# this cell is to connect my google drive with colab notebook to get data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qNVwgeH_lqbM"
   },
   "outputs": [],
   "source": [
    "# this cell is for geting data from path in the drive\n",
    "path = '/content/drive/My Drive/train/train.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMdeR89Llqbs"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) # last check to make sure about nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGlbaSUTlqbw"
   },
   "source": [
    "To make sure about using same sample data in each notebook, I always get same data and divide with same random state and test_size for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4a-3vu6Nlqb_"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will split my train and test to X and y as text and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ezso4Q7flqcE"
   },
   "outputs": [],
   "source": [
    "train_target = train_data.sentiment\n",
    "train_texts = train_data.review_clean\n",
    "\n",
    "test_target = test_data.sentiment\n",
    "test_texts = test_data.review_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like previous notebook, I inspired by https://www.kaggle.com/muonneutrino/sentiment-analysis-with-amazon-reviews to build model. I changed layers and layer types to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qxLjVxQlqcO"
   },
   "outputs": [],
   "source": [
    "# I get together my text\n",
    "def converting_texts(texts):\n",
    "    collected_texts = []\n",
    "    for text in texts:\n",
    "        collected_texts.append(text)\n",
    "    return collected_texts\n",
    "        \n",
    "train_texts = converting_texts(train_texts)\n",
    "test_texts = converting_texts(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to tokenize my text and padding sequences before modeling my data. I will use Keras proprocessing tools for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4JTCuhslqcW"
   },
   "outputs": [],
   "source": [
    "max_feat= 12000 #seting max features to define max number of tokenizer words\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_feat)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "# updates internal vocabulary based on a list of texts\n",
    "# in the case where texts contains lists, we assume each entry of the lists to be a token\n",
    "# required before using texts_to_sequences or texts_to_matrix\n",
    "\n",
    "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
    "test_texts = tokenizer.texts_to_sequences(test_texts)\n",
    "# transforms each text in texts to a sequence of integers\n",
    "# Only top num_words-1 most frequent words will be taken into account \n",
    "# Only words known by the tokenizer will be taken into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use batches productively, I need to turn my sequences to same lenght. I prefer to set everything to maximum lenght of the longest sentence in train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QjtN-UPJlqcb"
   },
   "outputs": [],
   "source": [
    "max_len = max(len(train_ex) for train_ex in train_texts) #setting the max length\n",
    "\n",
    "# using pad_sequence tool from Keras\n",
    "# transforms a list of sequences to into a 2D Numpy array of shape \n",
    "# the maxlen argument for the length of the longest sequence in the list\n",
    "train_texts = pad_sequences(train_texts, maxlen=max_len)\n",
    "test_texts = pad_sequences(test_texts, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, I reduced the layer number in CNN. I set one convolutional layer with batch normalization and max pooling. Additionaly, one convolutional layer with global max pooling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2TpNmPSMlqcg"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    sequences = layers.Input(shape=(max_len,))\n",
    "    embedded = layers.Embedding(max_feat, 64)(sequences)\n",
    "    x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(3)(x)\n",
    "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Model to Pre-processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "t6Po8kWmlqcw",
    "outputId": "8dbd125b-97a5-41e1-9248-300c5d89924f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.2157 - binary_accuracy: 0.9233 - val_loss: 0.1995 - val_binary_accuracy: 0.9208\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 55s 111ms/step - loss: 0.1456 - binary_accuracy: 0.9436 - val_loss: 0.1830 - val_binary_accuracy: 0.9384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9fd4730048>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_target, \n",
    "    train_labels, \n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    validation_data=(test_texts, test_target) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives good results with less loss and high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model with CuDNNGRU Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I changed the layer types for RNN to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_72Lbyablqd1"
   },
   "outputs": [],
   "source": [
    "def build_rnn_model():\n",
    "    sequences = layers.Input(shape=(max_len,))\n",
    "    embedded = layers.Embedding(max_feat, 64)(sequences)\n",
    "    x = layers.CuDNNGRU(128, return_sequences=True)(embedded)\n",
    "    x = layers.CuDNNGRU(128)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "rnn_model = build_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "DEz1HZGklqd-",
    "outputId": "20633893-b53b-43aa-d1a6-cb2c4fd11d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "500/500 [==============================] - 331s 661ms/step - loss: 0.2204 - binary_accuracy: 0.9177 - val_loss: 0.1871 - val_binary_accuracy: 0.9280\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 329s 658ms/step - loss: 0.1611 - binary_accuracy: 0.9361 - val_loss: 0.1792 - val_binary_accuracy: 0.9369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9fd03a2240>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(\n",
    "    train_texts, \n",
    "    train_target, \n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    validation_data=(test_texts, test_target) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives a bit better than CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with LSTM Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try LSTM layers this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mN8DwiCxlqeI"
   },
   "outputs": [],
   "source": [
    "def build_lstm_model():\n",
    "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
    "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
    "    x = layers.LSTM(128, return_sequences=True)(embedded)\n",
    "    x = layers.LSTM(128)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "rnn_model = build_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "38nly0ekoXmf",
    "outputId": "fb3238e2-6f5e-4db4-c6e1-e7cedaa3fdf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "500/500 [==============================] - 392s 783ms/step - loss: 0.2149 - binary_accuracy: 0.9245 - val_loss: 0.1718 - val_binary_accuracy: 0.9322\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 391s 781ms/step - loss: 0.1652 - binary_accuracy: 0.9367 - val_loss: 0.1656 - val_binary_accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9fd639e048>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(\n",
    "    train_texts, \n",
    "    train_target, \n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    validation_data=(test_texts, test_target) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSw7jRbfvVOq"
   },
   "source": [
    "It gives higher values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing All 5 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked all results and there is no huge differences between train and validation results which show overfitting. So, I will compare validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=[\"Model\", \"val_loss\",'val_acc']) # to see all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # written in results \n",
    "     \"Model\": 'CNN-3-Conv' ,\"val_loss\": 0.2632  ,'val_acc' : 0.9175}, ignore_index=True)\n",
    "df_results = df_results.append({       # written in results \n",
    "     \"Model\": 'RNN-2-GRU' ,\"val_loss\": 0.1615  ,'val_acc' : 0.9377}, ignore_index=True)\n",
    "df_results = df_results.append({       # written in results \n",
    "     \"Model\": 'CNN-2-Conv' ,\"val_loss\": 0.1839  ,'val_acc' : 0.9384}, ignore_index=True)\n",
    "df_results = df_results.append({       # written in results \n",
    "     \"Model\": 'RNN-2-CuDNNGRU' ,\"val_loss\": 0.1792  ,'val_acc' : 0.9369}, ignore_index=True)\n",
    "df_results = df_results.append({       # written in results \n",
    "     \"Model\": 'RNN-2-LSTM' ,\"val_loss\": 0.1656  ,'val_acc' : 0.9375}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CNN-3-Conv</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.9175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RNN-2-GRU</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.9377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CNN-2-Conv</td>\n",
       "      <td>0.1839</td>\n",
       "      <td>0.9384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RNN-2-CuDNNGRU</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RNN-2-LSTM</td>\n",
       "      <td>0.1656</td>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  val_loss  val_acc\n",
       "0      CNN-3-Conv    0.2632   0.9175\n",
       "1       RNN-2-GRU    0.1615   0.9377\n",
       "2      CNN-2-Conv    0.1839   0.9384\n",
       "3  RNN-2-CuDNNGRU    0.1792   0.9369\n",
       "4      RNN-2-LSTM    0.1656   0.9375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to accuracy CNN with 2-Conv is highest but its loss is higher than RNN-2-GRU also. So, I decided to best model with Keras as RNN with GRU layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.barplot(x='Model', y= 'val_loss',data=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Advices:\n",
    "\n",
    "- More layers can be added.\n",
    "- Models can be run for more epoches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Keras_LSTM_GRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
