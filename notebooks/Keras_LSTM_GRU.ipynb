{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Keras_LSTM_GRU.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8neitrJ7lqZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.python.keras import models, layers, optimizers\n",
        "\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "import re\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6U-m6shlqZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6BTwr2wlqZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import models, layers, optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWWebikplqZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer, text_to_word_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjHvx-JMlqaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8EBMG9Plqaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "40f2a018-a5aa-434c-c1ef-1d60f44d0e3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tizysXA9lqaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNVwgeH_lqbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/train/train.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "284qPIINlqbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba13fe0d-f581-4557-ad18-8363d68a75b7"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79979, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6bU_NxFlqbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8d79c04f-b59a-42ea-b80c-e92c9184c8ba"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_clean    21\n",
              "sentiment        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMdeR89Llqbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGlbaSUTlqbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a-3vu6Nlqb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = train_test_split(df, test_size=0.2,random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezso4Q7flqcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_data.sentiment\n",
        "train_texts = train_data.review_clean\n",
        "\n",
        "test_labels = test_data.sentiment\n",
        "test_texts = test_data.review_clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qxLjVxQlqcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NON_ALPHANUM = re.compile(r'[\\W]')\n",
        "NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
        "def normalize_texts(texts):\n",
        "    normalized_texts = []\n",
        "    for text in texts:\n",
        "        lower = text.lower()\n",
        "        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\n",
        "        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n",
        "        normalized_texts.append(no_non_ascii)\n",
        "    return normalized_texts\n",
        "        \n",
        "train_texts = normalize_texts(train_texts)\n",
        "test_texts = normalize_texts(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4JTCuhslqcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_FEATURES = 12000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
        "test_texts = tokenizer.texts_to_sequences(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjtN-UPJlqcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
        "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
        "test_texts = pad_sequences(test_texts, maxlen=MAX_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TpNmPSMlqcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
        "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
        "    x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool1D(3)(x)\n",
        "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
        "    x = layers.GlobalMaxPool1D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(100, activation='relu')(x)\n",
        "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer='rmsprop',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['binary_accuracy']\n",
        "    )\n",
        "    return model\n",
        "    \n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Po8kWmlqcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8dbd125b-97a5-41e1-9248-300c5d89924f"
      },
      "source": [
        "model.fit(\n",
        "    train_texts, \n",
        "    train_labels, \n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    validation_data=(test_texts, test_labels) )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.2157 - binary_accuracy: 0.9233 - val_loss: 0.1995 - val_binary_accuracy: 0.9208\n",
            "Epoch 2/2\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.1456 - binary_accuracy: 0.9436 - val_loss: 0.1830 - val_binary_accuracy: 0.9384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9fd4730048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_72Lbyablqd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_rnn_model():\n",
        "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
        "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
        "    x = layers.CuDNNGRU(128, return_sequences=True)(embedded)\n",
        "    x = layers.CuDNNGRU(128)(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dense(100, activation='relu')(x)\n",
        "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer='rmsprop',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['binary_accuracy']\n",
        "    )\n",
        "    return model\n",
        "    \n",
        "rnn_model = build_rnn_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEz1HZGklqd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "20633893-b53b-43aa-d1a6-cb2c4fd11d3b"
      },
      "source": [
        "rnn_model.fit(\n",
        "    train_texts, \n",
        "    train_labels, \n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    validation_data=(test_texts, test_labels) )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "500/500 [==============================] - 331s 661ms/step - loss: 0.2204 - binary_accuracy: 0.9177 - val_loss: 0.1871 - val_binary_accuracy: 0.9280\n",
            "Epoch 2/2\n",
            "500/500 [==============================] - 329s 658ms/step - loss: 0.1611 - binary_accuracy: 0.9361 - val_loss: 0.1792 - val_binary_accuracy: 0.9369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9fd03a2240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN8DwiCxlqeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lstm_model():\n",
        "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
        "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
        "    x = layers.LSTM(128, return_sequences=True)(embedded)\n",
        "    x = layers.LSTM(128)(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dense(100, activation='relu')(x)\n",
        "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer='rmsprop',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['binary_accuracy']\n",
        "    )\n",
        "    return model\n",
        "    \n",
        "rnn_model = build_lstm_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38nly0ekoXmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fb3238e2-6f5e-4db4-c6e1-e7cedaa3fdf1"
      },
      "source": [
        "rnn_model.fit(\n",
        "    train_texts, \n",
        "    train_labels, \n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    validation_data=(test_texts, test_labels) )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "500/500 [==============================] - 392s 783ms/step - loss: 0.2149 - binary_accuracy: 0.9245 - val_loss: 0.1718 - val_binary_accuracy: 0.9322\n",
            "Epoch 2/2\n",
            "500/500 [==============================] - 391s 781ms/step - loss: 0.1652 - binary_accuracy: 0.9367 - val_loss: 0.1656 - val_binary_accuracy: 0.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9fd639e048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g159Cr0dpS-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d23986-3a2d-45e8-c8e9-616667f18576"
      },
      "source": [
        "len(train_texts)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63983"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mReahkAUvLeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9a29661-a9bd-4b10-dc6a-ae7f69706cf0"
      },
      "source": [
        "len(test_texts)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSw7jRbfvVOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}